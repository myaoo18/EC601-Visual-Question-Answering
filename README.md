# EC601-Visual-Question-Answering
The mission of this project is to reimplement the baseline of VQA from Vahid Kazemi and Ali Elqursh’s paper, Show, Ask, Attend, and Answer: A Strong Baseline For Visual Question Answering, and to compare their method from previously published work on the popular VQA v1 dataset. The team hopes to replace and inject various implementations into these researcher’s models in order to achieve the most efficient Visual Question Answering task. Moreover, this project aims to provide simple analysis of the results for future researchers to build on. 
